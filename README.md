# Vision-Transformer-ViT

## Overview
The Vision Transformer (ViT) is a neural network architecture that applies the transformer model, originally designed for natural language processing tasks, to computer vision. Instead of using conventional convolutional layers, ViT divides an image into fixed-size patches, linearly embeds them into vectors, and feeds the sequence of vectors into a transformer. The model then outputs classifications or other visual predictions. It has achieved state-of-the-art performance on several benchmarks, challenging the dominance of traditional convolutional neural networks (CNNs) in the vision domain.

## Dependencies
- Python
- OpenCV
- Numpy
- Pytorch
- Numpy
- timm
- PIL
  
## Model Architecture

  <p align="center">
  <img width="321" alt="vit" src="https://github.com/Naveench7/Iterative-Closest-Point-ICP-/assets/100085132/dfacee1a-9d71-499c-9252-b3fcd771be67">
</p>

## Result

  <p align="center">
  <img width="321" alt="vit" src="https://github.com/Naveench7/Image-Stiching/assets/100085132/7a6c1aaa-5e19-44b6-a684-7f2158b3ccbe">
</p>



